{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b4c20f",
   "metadata": {},
   "source": [
    "# Final Model — Hyperparameter Tuning & Submission\n",
    "CW1 — Tuning top models, stacking, and generating test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabeb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib.util\n",
    "from sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "missing = [pkg for pkg in ('xgboost', 'lightgbm') if importlib.util.find_spec(pkg) is None]\n",
    "if missing:\n",
    "    raise ImportError(f\"Missing dependency(ies): {', '.join(missing)}. Install with `pip install -r requirements.txt`.\")\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    Resolve CW1 project root robustly.\n",
    "    Priority:\n",
    "    1) CW1_PROJECT_ROOT env var (if set)\n",
    "    2) Current working directory, then each parent directory\n",
    "    Root is identified by presence of both required data files.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    env_root = os.environ.get(\"CW1_PROJECT_ROOT\")\n",
    "    if env_root:\n",
    "        candidates.append(Path(env_root).expanduser().resolve())\n",
    "\n",
    "    cwd = Path.cwd().resolve()\n",
    "    candidates.extend([cwd, *cwd.parents])\n",
    "\n",
    "    checked = []\n",
    "    for root in candidates:\n",
    "        checked.append(root)\n",
    "        train_path = root / \"data\" / \"CW1_train.csv\"\n",
    "        test_path = root / \"data\" / \"CW1_test.csv\"\n",
    "        if train_path.is_file() and test_path.is_file():\n",
    "            return root\n",
    "\n",
    "    checked_msg = \"\\n\".join(f\"  - {p}\" for p in checked)\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate CW1 project root.\\n\"\n",
    "        \"Expected files:\\n\"\n",
    "        \"  - data/CW1_train.csv\\n\"\n",
    "        \"  - data/CW1_test.csv\\n\"\n",
    "        f\"Current working directory: {cwd}\\n\"\n",
    "        \"Directories checked:\\n\"\n",
    "        f\"{checked_msg}\\n\"\n",
    "        \"If needed, set CW1_PROJECT_ROOT to your repo root and rerun this cell.\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def require_file(path: Path, label: str = \"Required file\") -> Path:\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(\n",
    "            f\"{label} not found: {path}\\n\"\n",
    "            f\"PROJECT_ROOT resolved to: {PROJECT_ROOT}\\n\"\n",
    "            \"Check file names and repository structure.\"\n",
    "        )\n",
    "    return path\n",
    "\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0122b",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_csv(require_file(DATA_DIR / 'CW1_train.csv', 'Training CSV'))\n",
    "tst = pd.read_csv(require_file(DATA_DIR / 'CW1_test.csv', 'Test CSV'))\n",
    "\n",
    "y = trn['outcome']\n",
    "X = trn.drop(columns=['outcome'])\n",
    "\n",
    "# One-hot encode categoricals (same for train and test)\n",
    "X = pd.get_dummies(X, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "X_tst = pd.get_dummies(tst, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "\n",
    "# Ensure same columns in train and test\n",
    "X_tst = X_tst.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"Train: {X.shape}, Test: {X_tst.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1d7c4",
   "metadata": {},
   "source": [
    "## 2. Tune Histogram Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'max_iter': [300, 500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_leaf': [5, 10, 20, 30],\n",
    "    'max_features': [0.5, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "gb_search = RandomizedSearchCV(\n",
    "    HistGradientBoostingRegressor(random_state=42),\n",
    "    gb_params,\n",
    "    n_iter=60,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gb_search.fit(X, y)\n",
    "\n",
    "print(f\"Best R²: {gb_search.best_score_:.4f}\")\n",
    "print(f\"Best params: {gb_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db937f",
   "metadata": {},
   "source": [
    "## 3. Tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'num_leaves': [15, 31, 63, 127],\n",
    "    'min_child_samples': [5, 10, 20, 30],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1.0],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    lgb.LGBMRegressor(random_state=42, verbosity=-1, n_jobs=1),\n",
    "    lgb_params,\n",
    "    n_iter=60,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "lgb_search.fit(X, y)\n",
    "\n",
    "print(f\"Best R²: {lgb_search.best_score_:.4f}\")\n",
    "print(f\"Best params: {lgb_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300445c",
   "metadata": {},
   "source": [
    "## 4. Tune XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'min_child_weight': [1, 3, 5, 10],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1.0],\n",
    "    'reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb.XGBRegressor(random_state=42, verbosity=0, n_jobs=1),\n",
    "    xgb_params,\n",
    "    n_iter=60,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "xgb_search.fit(X, y)\n",
    "\n",
    "print(f\"Best R²: {xgb_search.best_score_:.4f}\")\n",
    "print(f\"Best params: {xgb_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612e17f",
   "metadata": {},
   "source": [
    "## 5. Tune Random Forest\n",
    "Manual grid search (faster than RandomizedSearchCV for RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {'n_estimators': 500, 'max_depth': 15, 'min_samples_leaf': 5, 'max_features': 'sqrt'},\n",
    "    {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 2, 'max_features': 0.5},\n",
    "    {'n_estimators': 500, 'max_depth': None, 'min_samples_leaf': 5, 'max_features': 'sqrt'},\n",
    "]\n",
    "\n",
    "best_rf_score = -np.inf\n",
    "best_rf_params = None\n",
    "for i, params in enumerate(configs):\n",
    "    rf = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(rf, X, y, cv=kf, scoring='r2', n_jobs=1)\n",
    "    print(f\"Config {i+1}: R² = {scores.mean():.4f} ± {scores.std():.4f}  {params}\")\n",
    "    if scores.mean() > best_rf_score:\n",
    "        best_rf_score = scores.mean()\n",
    "        best_rf_params = params\n",
    "\n",
    "print(f\"\\nBest RF config: {best_rf_params}\")\n",
    "best_rf = RandomForestRegressor(**best_rf_params, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df83425",
   "metadata": {},
   "source": [
    "## 6. Tuned Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20236fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = {\n",
    "    'Hist GB': gb_search.best_estimator_,\n",
    "    'LightGBM': lgb_search.best_estimator_,\n",
    "    'XGBoost': xgb_search.best_estimator_,\n",
    "    'Random Forest': best_rf,\n",
    "}\n",
    "\n",
    "tuned_results = {}\n",
    "for name, model in tuned_models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='r2', n_jobs=1)\n",
    "    tuned_results[name] = scores\n",
    "    print(f\"{name:25s}  R² = {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c16ef",
   "metadata": {},
   "source": [
    "## 7. Stacking Ensemble\n",
    "Using the top models as base estimators with Ridge as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('gb', gb_search.best_estimator_),\n",
    "        ('lgb', lgb_search.best_estimator_),\n",
    "        ('xgb', xgb_search.best_estimator_),\n",
    "        ('rf', best_rf),\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=kf,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "stack_scores = cross_val_score(stack, X, y, cv=kf, scoring='r2', n_jobs=1)\n",
    "print(f\"Stacking Ensemble          R² = {stack_scores.mean():.4f} ± {stack_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f6687",
   "metadata": {},
   "source": [
    "## 8. Simple Blending\n",
    "Average predictions from the top models — sometimes more robust than stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.fitted_models_ = []\n",
    "        for model in self.models:\n",
    "            m = clone(model)\n",
    "            m.fit(X, y)\n",
    "            self.fitted_models_.append(m)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.column_stack([m.predict(X) for m in self.fitted_models_])\n",
    "        if self.weights is not None:\n",
    "            return np.average(preds, axis=1, weights=self.weights)\n",
    "        return preds.mean(axis=1)\n",
    "\n",
    "blend = BlendingRegressor([\n",
    "    gb_search.best_estimator_,\n",
    "    lgb_search.best_estimator_,\n",
    "    xgb_search.best_estimator_,\n",
    "    best_rf,\n",
    "])\n",
    "\n",
    "blend_scores = cross_val_score(blend, X, y, cv=kf, scoring='r2', n_jobs=1)\n",
    "print(f\"Blending (equal weights)   R² = {blend_scores.mean():.4f} ± {blend_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da78887",
   "metadata": {},
   "source": [
    "## 9. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9191c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {**tuned_results}\n",
    "all_results['Stacking'] = stack_scores\n",
    "all_results['Blending'] = blend_scores\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Model': all_results.keys(),\n",
    "    'Mean R²': [v.mean() for v in all_results.values()],\n",
    "    'Std R²': [v.std() for v in all_results.values()]\n",
    "}).sort_values('Mean R²', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "pd.DataFrame(all_results).boxplot(ax=ax, vert=False)\n",
    "ax.set_xlabel('R² (5-fold CV)')\n",
    "ax.set_title('Final Model Comparison (Tuned)')\n",
    "plt.tight_layout()\n",
    "plot_path = OUTPUT_DIR / 'final_model_comparison.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved plot to: {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a74c9",
   "metadata": {},
   "source": [
    "## 10. Generate Submission\n",
    "Select the best model and produce the submission CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ee590",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = summary.iloc[0]['Model']\n",
    "print(f\"Best model: {best_name}\")\n",
    "\n",
    "if best_name == 'Stacking':\n",
    "    best_model = stack\n",
    "elif best_name == 'Blending':\n",
    "    best_model = blend\n",
    "else:\n",
    "    best_model = tuned_models[best_name]\n",
    "\n",
    "# Fit on full training data and predict\n",
    "final_model = clone(best_model)\n",
    "final_model.fit(X, y)\n",
    "yhat = final_model.predict(X_tst)\n",
    "\n",
    "# Save submission\n",
    "student_id = 'k23051742'\n",
    "submission_path = OUTPUT_DIR / f'CW1_submission_{student_id}.csv'\n",
    "out = pd.DataFrame({'yhat': yhat})\n",
    "out.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to: {submission_path}\")\n",
    "print(f\"Submission saved: {len(yhat)} predictions\")\n",
    "print(f\"Prediction range: [{yhat.min():.2f}, {yhat.max():.2f}]\")\n",
    "print(f\"Prediction mean: {yhat.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
